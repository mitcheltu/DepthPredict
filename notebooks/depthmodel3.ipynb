{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aab52952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T11:03:17.853310Z",
     "iopub.status.busy": "2025-09-04T11:03:17.852964Z",
     "iopub.status.idle": "2025-09-04T11:03:39.901485Z",
     "shell.execute_reply": "2025-09-04T11:03:39.900157Z"
    },
    "papermill": {
     "duration": 22.054956,
     "end_time": "2025-09-04T11:03:39.903349",
     "exception": false,
     "start_time": "2025-09-04T11:03:17.848393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import torch.nn.functional as F_nn\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import timm\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "def paired_transform(color_img, depth_img, output_size=224, max_depth=10.0, apply_color_jitter=True):\n",
    "    if random.random() > 0.5:\n",
    "        color_img = F.hflip(color_img)\n",
    "        depth_img = F.hflip(depth_img)\n",
    "\n",
    "    angle = random.uniform(-15, 15)\n",
    "    color_img = F.rotate(color_img, angle, interpolation=Image.BILINEAR)\n",
    "    depth_img = F.rotate(depth_img, angle, interpolation=Image.NEAREST)\n",
    "\n",
    "    i, j, h, w = transforms.RandomResizedCrop.get_params(\n",
    "        color_img, scale=(0.8, 1.0), ratio=(1.0, 1.0)\n",
    "    )\n",
    "    color_img = F.resized_crop(color_img, i, j, h, w, size=(output_size, output_size))\n",
    "    depth_img = F.resized_crop(depth_img, i, j, h, w, size=(output_size, output_size))\n",
    "\n",
    "    if apply_color_jitter:\n",
    "        color_jitter = transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3)\n",
    "        color_img = color_jitter(color_img)\n",
    "\n",
    "    # RGB → tensor\n",
    "    color_tensor = F.to_tensor(color_img)\n",
    "    color_tensor = F.normalize(color_tensor, mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "\n",
    "    # Depth → tensor (meters)\n",
    "    depth_np = np.array(depth_img).astype(np.float32) / 1000.0\n",
    "    \n",
    "    # Augment depth (after cropping & before clamping)\n",
    "    if random.random() < 0.3:\n",
    "        depth_np *= random.uniform(0.9, 1.1)   # brightness-like scaling\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        depth_np = depth_np ** random.uniform(0.7, 1.3)   # gamma\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        depth_np += np.random.normal(0, 0.01, depth_np.shape)  # Gaussian noise\n",
    "\n",
    "    \n",
    "    depth_tensor = torch.from_numpy(depth_np).unsqueeze(0)\n",
    "    depth_tensor = torch.clamp(depth_tensor, 0, max_depth)\n",
    "\n",
    "    return color_tensor, depth_tensor\n",
    "    \n",
    "\n",
    "class DepthDataset(Dataset):\n",
    "    def __init__(self, data_dir, paired_transform=None, max_depth=10.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir (str): Path to folder containing 'colors/' and 'depths/' subfolders.\n",
    "            paired_transform (callable, optional): Function to apply same geometric transform to both RGB and depth.\n",
    "            max_depth (float): Maximum depth value to scale depth maps (in meters).\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.paired_transform = paired_transform\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "        # Paths to color and depth folders\n",
    "        self.color_dir = os.path.join(data_dir, \"colors\")\n",
    "        self.depth_dir = os.path.join(data_dir, \"depths\")\n",
    "\n",
    "        # List all RGB color images\n",
    "        self.color_files = sorted([f for f in os.listdir(self.color_dir) if f.endswith(\"_colors.png\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.color_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load RGB image\n",
    "        color_path = os.path.join(self.color_dir, self.color_files[idx])\n",
    "        color_img = Image.open(color_path).convert(\"RGB\")\n",
    "\n",
    "        # Load corresponding depth image\n",
    "        depth_file = self.color_files[idx].replace(\"_colors.png\", \"_depth.png\")\n",
    "        depth_path = os.path.join(self.depth_dir, depth_file)\n",
    "        depth_img = Image.open(depth_path)\n",
    "\n",
    "        # Apply paired transform if provided\n",
    "        if self.paired_transform:\n",
    "            color_tensor, depth_tensor = self.paired_transform(color_img, depth_img)\n",
    "        else:\n",
    "            # Convert RGB to tensor and normalize\n",
    "            color_tensor = T.ToTensor()(color_img)\n",
    "            color_tensor = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                       std=[0.229, 0.224, 0.225])(color_tensor)\n",
    "            # Convert depth to tensor and scale to meters\n",
    "            depth_np = np.array(depth_img).astype(np.float32) / 1000.0  # mm → meters\n",
    "            depth_tensor = torch.from_numpy(depth_np).unsqueeze(0)\n",
    "            depth_tensor = torch.clamp(depth_tensor, 0, self.max_depth)\n",
    "\n",
    "        return color_tensor, depth_tensor\n",
    "\n",
    "\n",
    "class DepthModel(nn.Module):\n",
    "    def __init__(self, backbone_name='efficientnet_b3', pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # --------------------------\n",
    "        # Encoder: pretrained CNN\n",
    "        # --------------------------\n",
    "        # Use features_only=True to get intermediate feature maps for decoder\n",
    "        self.encoder = timm.create_model(backbone_name, pretrained=pretrained, features_only=True)\n",
    "        \n",
    "        # Channels of encoder feature maps at each stage\n",
    "        encoder_channels = self.encoder.feature_info.channels()  # e.g., [40, 48, 136, 384]\n",
    "        last_ch = encoder_channels[-1]\n",
    "\n",
    "        # --------------------------\n",
    "        # Simple decoder: upsample to original resolution\n",
    "        # --------------------------\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(last_ch, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "\n",
    "            nn.Conv2d(64, 1, kernel_size=3, padding=1)  # Output: single-channel depth map\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder forward: returns list of feature maps at different stages\n",
    "        features = self.encoder(x)\n",
    "        x = features[-1]  # Use last-stage feature map for decoder\n",
    "\n",
    "        # Decode to depth map\n",
    "        depth = self.decoder(x)\n",
    "        # Unsample to match input size\n",
    "        depth = F_nn.interpolate(depth, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "425a2a2c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-04T11:03:39.909728Z",
     "iopub.status.busy": "2025-09-04T11:03:39.909379Z",
     "iopub.status.idle": "2025-09-04T13:24:55.904305Z",
     "shell.execute_reply": "2025-09-04T13:24:55.902594Z"
    },
    "papermill": {
     "duration": 8476.000555,
     "end_time": "2025-09-04T13:24:55.906498",
     "exception": false,
     "start_time": "2025-09-04T11:03:39.905943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5d45c0c4924815b10150b2965482f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/49.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10 (Frozen Encoder)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:43<00:00,  5.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.6969 | Val Loss: 1.9382 | Val RMSE: 1.3922 m\n",
      "✅ Best model saved.\n",
      "\n",
      "Epoch 2/10 (Frozen Encoder)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:35<00:00,  5.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8146 | Val Loss: 1.6446 | Val RMSE: 1.2824 m\n",
      "✅ Best model saved.\n",
      "\n",
      "Epoch 3/10 (Frozen Encoder)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:37<00:00,  5.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4265 | Val Loss: 1.6849 | Val RMSE: 1.2980 m\n",
      "\n",
      "Epoch 4/10 (Frozen Encoder)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:37<00:00,  5.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1774 | Val Loss: 1.7670 | Val RMSE: 1.3293 m\n",
      "\n",
      "Epoch 5/10 (Frozen Encoder)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:35<00:00,  5.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2991 | Val Loss: 1.2664 | Val RMSE: 1.1253 m\n",
      "✅ Best model saved.\n",
      "\n",
      "Epoch 6/10 (Frozen Encoder)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:36<00:00,  5.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1601 | Val Loss: 1.3712 | Val RMSE: 1.1710 m\n",
      "\n",
      "Epoch 7/10 (Frozen Encoder)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:36<00:00,  5.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0705 | Val Loss: 0.9960 | Val RMSE: 0.9980 m\n",
      "✅ Best model saved.\n",
      "\n",
      "Epoch 8/10 (Frozen Encoder)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:39<00:00,  5.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1693 | Val Loss: 1.0636 | Val RMSE: 1.0313 m\n",
      "\n",
      "Epoch 9/10 (Frozen Encoder)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:39<00:00,  5.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1247 | Val Loss: 1.5226 | Val RMSE: 1.2339 m\n",
      "\n",
      "Epoch 10/10 (Frozen Encoder)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:39<00:00,  5.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0843 | Val Loss: 1.3552 | Val RMSE: 1.1641 m\n",
      "Training complete\n",
      "\n",
      "Epoch 1/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [03:07<00:00,  9.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9890 | Val Loss: 1.3862 | Val RMSE: 1.1774 m\n",
      "\n",
      "Epoch 2/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:57<00:00,  9.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8503 | Val Loss: 1.0904 | Val RMSE: 1.0442 m\n",
      "\n",
      "Epoch 3/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:54<00:00,  9.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8586 | Val Loss: 0.9287 | Val RMSE: 0.9637 m\n",
      "✅ Best model saved.\n",
      "\n",
      "Epoch 4/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:55<00:00,  9.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8378 | Val Loss: 0.9828 | Val RMSE: 0.9914 m\n",
      "\n",
      "Epoch 5/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:56<00:00,  9.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7803 | Val Loss: 1.0295 | Val RMSE: 1.0146 m\n",
      "\n",
      "Epoch 6/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:52<00:00,  9.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7581 | Val Loss: 0.8720 | Val RMSE: 0.9338 m\n",
      "✅ Best model saved.\n",
      "\n",
      "Epoch 7/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:54<00:00,  9.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7349 | Val Loss: 0.9666 | Val RMSE: 0.9831 m\n",
      "\n",
      "Epoch 8/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:52<00:00,  9.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6795 | Val Loss: 1.0922 | Val RMSE: 1.0451 m\n",
      "\n",
      "Epoch 9/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [03:04<00:00,  9.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6293 | Val Loss: 0.8665 | Val RMSE: 0.9309 m\n",
      "✅ Best model saved.\n",
      "\n",
      "Epoch 10/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:54<00:00,  9.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6568 | Val Loss: 1.1461 | Val RMSE: 1.0706 m\n",
      "\n",
      "Epoch 11/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:53<00:00,  9.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6608 | Val Loss: 0.9372 | Val RMSE: 0.9681 m\n",
      "\n",
      "Epoch 12/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:55<00:00,  9.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6115 | Val Loss: 0.9403 | Val RMSE: 0.9697 m\n",
      "\n",
      "Epoch 13/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:53<00:00,  9.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5823 | Val Loss: 0.9089 | Val RMSE: 0.9533 m\n",
      "\n",
      "Epoch 14/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:56<00:00,  9.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6050 | Val Loss: 0.9910 | Val RMSE: 0.9955 m\n",
      "\n",
      "Epoch 15/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:53<00:00,  9.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5922 | Val Loss: 0.8633 | Val RMSE: 0.9291 m\n",
      "✅ Best model saved.\n",
      "\n",
      "Epoch 16/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:54<00:00,  9.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6034 | Val Loss: 0.9030 | Val RMSE: 0.9503 m\n",
      "\n",
      "Epoch 17/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:51<00:00,  9.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5267 | Val Loss: 0.6373 | Val RMSE: 0.7983 m\n",
      "✅ Best model saved.\n",
      "\n",
      "Epoch 18/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:57<00:00,  9.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5557 | Val Loss: 1.1782 | Val RMSE: 1.0855 m\n",
      "\n",
      "Epoch 19/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:53<00:00,  9.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5739 | Val Loss: 0.9841 | Val RMSE: 0.9920 m\n",
      "\n",
      "Epoch 20/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:54<00:00,  9.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5997 | Val Loss: 0.8024 | Val RMSE: 0.8958 m\n",
      "\n",
      "Epoch 21/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:53<00:00,  9.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5262 | Val Loss: 0.7489 | Val RMSE: 0.8654 m\n",
      "\n",
      "Epoch 22/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:56<00:00,  9.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5193 | Val Loss: 0.9147 | Val RMSE: 0.9564 m\n",
      "\n",
      "Epoch 23/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:54<00:00,  9.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6084 | Val Loss: 0.9044 | Val RMSE: 0.9510 m\n",
      "\n",
      "Epoch 24/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:52<00:00,  9.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5827 | Val Loss: 0.7407 | Val RMSE: 0.8607 m\n",
      "\n",
      "Epoch 25/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:53<00:00,  9.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5975 | Val Loss: 0.9096 | Val RMSE: 0.9537 m\n",
      "\n",
      "Epoch 26/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:56<00:00,  9.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5172 | Val Loss: 0.9268 | Val RMSE: 0.9627 m\n",
      "\n",
      "Epoch 27/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:54<00:00,  9.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5695 | Val Loss: 0.9469 | Val RMSE: 0.9731 m\n",
      "\n",
      "Epoch 28/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:57<00:00,  9.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6316 | Val Loss: 0.7591 | Val RMSE: 0.8712 m\n",
      "\n",
      "Epoch 29/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:56<00:00,  9.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5627 | Val Loss: 0.9502 | Val RMSE: 0.9748 m\n",
      "\n",
      "Epoch 30/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:53<00:00,  9.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5882 | Val Loss: 1.0064 | Val RMSE: 1.0032 m\n",
      "\n",
      "Epoch 31/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:54<00:00,  9.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5745 | Val Loss: 1.0221 | Val RMSE: 1.0110 m\n",
      "\n",
      "Epoch 32/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:52<00:00,  9.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5586 | Val Loss: 1.0384 | Val RMSE: 1.0190 m\n",
      "\n",
      "Epoch 33/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:54<00:00,  9.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5631 | Val Loss: 0.9524 | Val RMSE: 0.9759 m\n",
      "\n",
      "Epoch 34/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:53<00:00,  9.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5620 | Val Loss: 0.7480 | Val RMSE: 0.8649 m\n",
      "\n",
      "Epoch 35/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:57<00:00,  9.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5811 | Val Loss: 0.8173 | Val RMSE: 0.9041 m\n",
      "\n",
      "Epoch 36/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:55<00:00,  9.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5790 | Val Loss: 0.8079 | Val RMSE: 0.8989 m\n",
      "\n",
      "Epoch 37/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:58<00:00,  9.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5636 | Val Loss: 0.8252 | Val RMSE: 0.9084 m\n",
      "\n",
      "Epoch 38/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:55<00:00,  9.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5793 | Val Loss: 0.9424 | Val RMSE: 0.9708 m\n",
      "\n",
      "Epoch 39/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:54<00:00,  9.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5516 | Val Loss: 0.7693 | Val RMSE: 0.8771 m\n",
      "\n",
      "Epoch 40/40 (Fine-tune)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:53<00:00,  9.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5463 | Val Loss: 1.0670 | Val RMSE: 1.0330 m\n",
      "Training complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6373271135183481"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Training Loop\n",
    "# --------------------------\n",
    "def train_depth_model(model, train_loader, val_loader, epochs=10, freeze_encoder=True, lr_head=1e-3, lr_finetune=1e-4, model_path=\"depth_model.pth\", best_val_loss=float(\"inf\")):\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if freeze_encoder:\n",
    "        for param in model.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr_head)\n",
    "    else:\n",
    "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr_finetune)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=3)\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs} {'(Frozen Encoder)' if freeze_encoder else '(Fine-tune)'}\")\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, depths in tqdm(train_loader):\n",
    "            images, depths = images.to(device), depths.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, depths)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, depths in val_loader:\n",
    "                images, depths = images.to(device), depths.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, depths)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        rmse = np.sqrt(val_loss)\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val RMSE: {rmse:.4f} m\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"✅ Best model saved.\")\n",
    "\n",
    "        # Scheduler step\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete\")\n",
    "    return best_val_loss\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Run training\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Device\n",
    "# --------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------------------------\n",
    "# Model\n",
    "# --------------------------\n",
    "model = DepthModel().to(device)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Datasets & Loaders\n",
    "# --------------------------\n",
    "train_folder = \"/kaggle/input/nyu-depth-split-dataset/nyu_split/train\"\n",
    "valid_folder = \"/kaggle/input/nyu-depth-split-dataset/nyu_split/val\"\n",
    "max_depth = 10\n",
    "\n",
    "train_dataset = DepthDataset(train_folder, paired_transform, max_depth)\n",
    "val_dataset = DepthDataset(valid_folder, paired_transform, max_depth)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# --------------------------\n",
    "# Freeze backbone initially\n",
    "# --------------------------\n",
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# --------------------------\n",
    "# Training Parameters\n",
    "# --------------------------\n",
    "num_epoch_head = 10       # Train classifier head first\n",
    "num_epoch_finetune = 40  # Fine-tune full model\n",
    "MODEL_PATH = \"/kaggle/working/depth_classifier.pth\"\n",
    "\n",
    "model = DepthModel().to(device)\n",
    "\n",
    "# 1. Train decoder head first\n",
    "best_val_loss = train_depth_model(model, train_loader, val_loader, epochs=num_epoch_head, freeze_encoder=True, \n",
    "                  model_path= MODEL_PATH)\n",
    "\n",
    "# 2. Fine-tune full model\n",
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "train_depth_model(model, train_loader, val_loader, epochs=num_epoch_finetune, freeze_encoder=False, \n",
    "                  model_path=\"depth_model.pth\", best_val_loss = best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21973676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T13:24:56.026551Z",
     "iopub.status.busy": "2025-09-04T13:24:56.025997Z",
     "iopub.status.idle": "2025-09-04T13:24:56.034125Z",
     "shell.execute_reply": "2025-09-04T13:24:56.032976Z"
    },
    "papermill": {
     "duration": 0.071608,
     "end_time": "2025-09-04T13:24:56.035972",
     "exception": false,
     "start_time": "2025-09-04T13:24:55.964364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # --------------------------\n",
    "# # Testing / Inference\n",
    "# # --------------------------\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(\"Using device:\", device)\n",
    "\n",
    "# # --------------------------\n",
    "# # Test Dataset & DataLoader\n",
    "# # --------------------------\n",
    "# test_folder = \"/kaggle/input/nyu-test-colors-depths/nyu2_test_colors_depths\"\n",
    "# test_dataset = DepthDataset(test_folder, paired_transform, max_depth=10.0)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# # Load trained model\n",
    "# test_model = DepthModel().to(device)\n",
    "# test_model.load_state_dict(torch.load(\n",
    "#     \"/kaggle/input/depthpredicterv2/pytorch/default/1/depth_classifierV2.pth\", \n",
    "#     map_location=device\n",
    "# ))\n",
    "# test_model.eval()\n",
    "\n",
    "# # Loss function for evaluation\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# # --------------------------\n",
    "# # Evaluation with tqdm\n",
    "# # --------------------------\n",
    "# val_loss, val_mae = 0.0, 0.0\n",
    "# with torch.no_grad():\n",
    "#     for images, depths in tqdm(test_loader, desc=\"Evaluating on test set\"):\n",
    "#         images, depths = images.to(device), depths.to(device)\n",
    "#         outputs = test_model(images)\n",
    "\n",
    "#         # Loss metrics\n",
    "#         mse_loss = criterion(outputs, depths)\n",
    "#         mae_loss = torch.mean(torch.abs(outputs - depths))\n",
    "\n",
    "#         val_loss += mse_loss.item() * images.size(0)\n",
    "#         val_mae += mae_loss.item() * images.size(0)\n",
    "\n",
    "# val_loss /= len(test_loader.dataset)\n",
    "# val_mae /= len(test_loader.dataset)\n",
    "# val_rmse = np.sqrt(val_loss)\n",
    "\n",
    "# print(f\"✅ Test Results -> MSE: {val_loss:.4f}, RMSE: {val_rmse:.4f} m, MAE: {val_mae:.4f} m\")\n",
    "\n",
    "# # --------------------------\n",
    "# # Visualization\n",
    "# # --------------------------\n",
    "# def show_predictions(model, dataset, num_samples=5):\n",
    "#     model.eval()\n",
    "#     fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "\n",
    "#     for i in tqdm(range(num_samples), desc=\"Visualizing predictions\"):\n",
    "#         color, depth_gt = dataset[i]\n",
    "#         color_batch = color.unsqueeze(0).to(device)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             depth_pred = model(color_batch).cpu().squeeze().numpy()\n",
    "\n",
    "#         depth_gt = depth_gt.squeeze().numpy()\n",
    "\n",
    "#         # Plot RGB\n",
    "#         axes[i, 0].imshow(np.transpose(color.numpy(), (1, 2, 0)))\n",
    "#         axes[i, 0].set_title(\"RGB Input\")\n",
    "#         axes[i, 0].axis(\"off\")\n",
    "\n",
    "#         # Plot Ground Truth Depth\n",
    "#         axes[i, 1].imshow(depth_gt, cmap=\"inferno\")\n",
    "#         axes[i, 1].set_title(\"Ground Truth Depth\")\n",
    "#         axes[i, 1].axis(\"off\")\n",
    "\n",
    "#         # Plot Predicted Depth\n",
    "#         axes[i, 2].imshow(depth_pred, cmap=\"inferno\")\n",
    "#         axes[i, 2].set_title(\"Predicted Depth\")\n",
    "#         axes[i, 2].axis(\"off\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Visualize predictions from test set\n",
    "# show_predictions(test_model, test_dataset, num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1198025,
     "sourceId": 2002504,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8200507,
     "sourceId": 12957283,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8201775,
     "sourceId": 12959543,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 441973,
     "modelInstanceId": 424483,
     "sourceId": 559837,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 441974,
     "modelInstanceId": 424484,
     "sourceId": 559838,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8508.045142,
   "end_time": "2025-09-04T13:24:59.627745",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-04T11:03:11.582603",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "20daeffafc8942a1806c96773f14490e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "366ca158db9746e1852e1892e3d209e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "512629321b8d447cbce9f2df1a322204": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b02aec948854baba87dc60f588a3423": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b1e65e5c697641d4a608acdf5059a74c",
       "placeholder": "​",
       "style": "IPY_MODEL_20daeffafc8942a1806c96773f14490e",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "6d5d45c0c4924815b10150b2965482f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5b02aec948854baba87dc60f588a3423",
        "IPY_MODEL_b2c1b788598a4ddd81d8981bcd2ba2dd",
        "IPY_MODEL_b54ecebe96da441c8bf809e0cd5abd96"
       ],
       "layout": "IPY_MODEL_512629321b8d447cbce9f2df1a322204",
       "tabbable": null,
       "tooltip": null
      }
     },
     "880e13ecc23e4868ae7b3f3736261087": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "932900245bdc4e5ea5d494a255607709": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b1e65e5c697641d4a608acdf5059a74c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2c1b788598a4ddd81d8981bcd2ba2dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d5bf381cd7824f7d881c5879af335bdf",
       "max": 49335454.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_366ca158db9746e1852e1892e3d209e2",
       "tabbable": null,
       "tooltip": null,
       "value": 49335454.0
      }
     },
     "b54ecebe96da441c8bf809e0cd5abd96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_932900245bdc4e5ea5d494a255607709",
       "placeholder": "​",
       "style": "IPY_MODEL_880e13ecc23e4868ae7b3f3736261087",
       "tabbable": null,
       "tooltip": null,
       "value": " 49.3M/49.3M [00:00&lt;00:00, 139MB/s]"
      }
     },
     "d5bf381cd7824f7d881c5879af335bdf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
