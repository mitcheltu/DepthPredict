{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b30a59d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T21:47:20.512495Z",
     "iopub.status.busy": "2025-09-04T21:47:20.512294Z",
     "iopub.status.idle": "2025-09-04T21:48:40.819567Z",
     "shell.execute_reply": "2025-09-04T21:48:40.818808Z"
    },
    "papermill": {
     "duration": 80.311796,
     "end_time": "2025-09-04T21:48:40.820945",
     "exception": false,
     "start_time": "2025-09-04T21:47:20.509149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-ema\r\n",
      "  Downloading torch_ema-0.3-py3-none-any.whl.metadata (415 bytes)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch-ema) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch-ema) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-ema) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torch-ema) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-ema) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch-ema) (2025.5.1)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torch-ema)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torch-ema)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torch-ema)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torch-ema)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torch-ema)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torch-ema)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torch-ema)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torch-ema)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torch-ema)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-ema) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch-ema) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-ema) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torch-ema)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-ema) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch-ema) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch-ema) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch-ema) (3.0.2)\r\n",
      "Downloading torch_ema-0.3-py3-none-any.whl (5.5 kB)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch-ema\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-ema-0.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b98a3d95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T21:48:40.861026Z",
     "iopub.status.busy": "2025-09-04T21:48:40.860736Z",
     "iopub.status.idle": "2025-09-04T21:48:59.826742Z",
     "shell.execute_reply": "2025-09-04T21:48:59.825827Z"
    },
    "papermill": {
     "duration": 18.988579,
     "end_time": "2025-09-04T21:48:59.828068",
     "exception": false,
     "start_time": "2025-09-04T21:48:40.839489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import torch.nn.functional as F_nn\n",
    "import random\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import timm\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "num_epoch_head = 10       # Train classifier head first\n",
    "num_epoch_finetune = 40  # Fine-tune full model\n",
    "\n",
    "def paired_transform(color_img, depth_img, output_size=224, max_depth=10.0, apply_color_jitter=True,\n",
    "                    epoch=0, total_epochs=50):\n",
    "    if random.random() > 0.5:\n",
    "        color_img = F.hflip(color_img)\n",
    "        depth_img = F.hflip(depth_img)\n",
    "\n",
    "    angle = random.uniform(-15, 15)\n",
    "    color_img = F.rotate(color_img, angle, interpolation=Image.BILINEAR)\n",
    "    depth_img = F.rotate(depth_img, angle, interpolation=Image.NEAREST)\n",
    "\n",
    "    i, j, h, w = T.RandomResizedCrop.get_params(\n",
    "        color_img, scale=(0.8, 1.0), ratio=(1.0, 1.0)\n",
    "    )\n",
    "    color_img = F.resized_crop(color_img, i, j, h, w, size=(output_size, output_size))\n",
    "    depth_img = F.resized_crop(depth_img, i, j, h, w, size=(output_size, output_size))\n",
    "\n",
    "    if apply_color_jitter:\n",
    "        color_jitter = T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3)\n",
    "        color_img = color_jitter(color_img)\n",
    "\n",
    "    # RGB → tensor\n",
    "    color_tensor = F.to_tensor(color_img)\n",
    "    color_tensor = F.normalize(color_tensor, mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "\n",
    "    # Depth → tensor (meters)\n",
    "    depth_np = np.array(depth_img).astype(np.float32) / 1000.0\n",
    "\n",
    "    \n",
    "    t = min(epoch / (0.3 * total_epochs), 1.0)  # ramp factor\n",
    "    \n",
    "   # Brightness-like scaling\n",
    "    if random.random() < 0.5:\n",
    "        scale = random.uniform(1 - 0.05*t, 1 + 0.05*t)\n",
    "        depth_np *= scale\n",
    "\n",
    "    # Gamma\n",
    "    if random.random() < 0.5:\n",
    "        gamma = random.uniform(1 - 0.2*t, 1 + 0.2*t)\n",
    "        depth_norm = np.clip(depth_np / max_depth, 1e-6, 1.0)\n",
    "        depth_np = (depth_norm ** gamma) * max_depth\n",
    "\n",
    "    # Gaussian noise\n",
    "    if random.random() < 0.5:\n",
    "        sigma = 0.005 + 0.02*t\n",
    "        depth_np += np.random.normal(0, sigma, depth_np.shape)\n",
    "\n",
    "    # Range dropout (simulate missing band)\n",
    "    if random.random() < 0.2:\n",
    "        h = depth_np.shape[0]\n",
    "        y0 = np.random.randint(0, h)\n",
    "        band = max(1, int(0.05*h))\n",
    "        depth_np[y0:y0+band, :] = 0.0\n",
    "\n",
    "    # Gaussian blur (defocus)\n",
    "    if random.random() < 0.2:\n",
    "        from scipy.ndimage import gaussian_filter\n",
    "        depth_np = gaussian_filter(depth_np, sigma=0.5)\n",
    "\n",
    "    \n",
    "    depth_tensor = torch.from_numpy(np.clip(depth_np, 0, max_depth)).unsqueeze(0)\n",
    "\n",
    "    return color_tensor, depth_tensor\n",
    "    \n",
    "\n",
    "class DepthDataset(Dataset):\n",
    "    def __init__(self, data_dir, paired_transform=None, max_depth=10.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir (str): Path to folder containing 'colors/' and 'depths/' subfolders.\n",
    "            paired_transform (callable, optional): Function to apply same geometric transform to both RGB and depth.\n",
    "            max_depth (float): Maximum depth value to scale depth maps (in meters).\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.paired_transform = paired_transform\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "        # Paths to color and depth folders\n",
    "        self.color_dir = os.path.join(data_dir, \"colors\")\n",
    "        self.depth_dir = os.path.join(data_dir, \"depths\")\n",
    "\n",
    "        # List all RGB color images\n",
    "        self.color_files = sorted([f for f in os.listdir(self.color_dir) if f.endswith(\"_colors.png\")])\n",
    "        \n",
    "        self.current_epoch = num_epoch_head\n",
    "        self.total_epochs = num_epoch_finetune  # default, can be updated\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.color_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load RGB image\n",
    "        color_path = os.path.join(self.color_dir, self.color_files[idx])\n",
    "        color_img = Image.open(color_path).convert(\"RGB\")\n",
    "\n",
    "        # Load corresponding depth image\n",
    "        depth_file = self.color_files[idx].replace(\"_colors.png\", \"_depth.png\")\n",
    "        depth_path = os.path.join(self.depth_dir, depth_file)\n",
    "        depth_img = Image.open(depth_path)\n",
    "\n",
    "        # Apply paired transform if provided\n",
    "        if self.paired_transform:\n",
    "            color_tensor, depth_tensor = paired_transform(color_img, depth_img,\n",
    "                                              epoch=self.current_epoch,\n",
    "                                              total_epochs=self.total_epochs)\n",
    "        else:\n",
    "            # Convert RGB to tensor and normalize\n",
    "            color_tensor = T.ToTensor()(color_img)\n",
    "            color_tensor = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                       std=[0.229, 0.224, 0.225])(color_tensor)\n",
    "            # Convert depth to tensor and scale to meters\n",
    "            depth_np = np.array(depth_img).astype(np.float32) / 1000.0  # mm → meters\n",
    "            depth_tensor = torch.from_numpy(depth_np).unsqueeze(0)\n",
    "            depth_tensor = torch.clamp(depth_tensor, 0, self.max_depth)\n",
    "\n",
    "        return color_tensor, depth_tensor\n",
    "\n",
    "    def set_epoch(self, epoch, total_epochs=None):\n",
    "        \"\"\"Update current epoch for curriculum depth augmentations\"\"\"\n",
    "        self.current_epoch = epoch\n",
    "        if total_epochs is not None:\n",
    "            self.total_epochs = total_epochs\n",
    "\n",
    "\n",
    "class DepthModel(nn.Module):\n",
    "    def __init__(self, backbone_name='efficientnet_b3', pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # --------------------------\n",
    "        # Encoder: pretrained CNN\n",
    "        # --------------------------\n",
    "        # Use features_only=True to get intermediate feature maps for decoder\n",
    "        self.encoder = timm.create_model(backbone_name, pretrained=pretrained, features_only=True)\n",
    "        \n",
    "        # Channels of encoder feature maps at each stage\n",
    "        encoder_channels = self.encoder.feature_info.channels()  # e.g., [40, 48, 136, 384]\n",
    "        last_ch = encoder_channels[-1]\n",
    "\n",
    "        # --------------------------\n",
    "        # Simple decoder: upsample to original resolution\n",
    "        # --------------------------\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(last_ch, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "\n",
    "            nn.Conv2d(64, 1, kernel_size=3, padding=1)  # Output: single-channel depth map\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder forward: returns list of feature maps at different stages\n",
    "        input_size = x.shape[2:]  # height and width of **original input image**\n",
    "        \n",
    "        features = self.encoder(x)\n",
    "        x_enc = features[-1]\n",
    "        \n",
    "        depth = self.decoder(x_enc)\n",
    "        depth = F_nn.interpolate(depth, size=input_size, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        return depth\n",
    "        \n",
    "# -------------------------\n",
    "# Custom Loss (Doesn't punish loss for outliers)\n",
    "# -------------------------\n",
    "class DepthLoss(nn.Module):\n",
    "    def __init__(self, delta=0.5, alpha=0.7):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def huber(self, pred, target):\n",
    "        diff = pred - target\n",
    "        abs_diff = diff.abs()\n",
    "        mask = target > 0  # ignore invalid zeros\n",
    "        diff = diff[mask]\n",
    "        abs_diff = abs_diff[mask]\n",
    "\n",
    "        loss = torch.where(\n",
    "            abs_diff <= self.delta,\n",
    "            0.5 * diff**2,\n",
    "            self.delta * (abs_diff - 0.5*self.delta)\n",
    "        )\n",
    "        return loss.mean()\n",
    "\n",
    "    def si_log(self, pred, target, eps=1e-6):\n",
    "        mask = target > 0\n",
    "        p = torch.log(pred[mask].clamp(min=eps))\n",
    "        t = torch.log(target[mask].clamp(min=eps))\n",
    "        d = p - t\n",
    "        return d.pow(2).mean() - d.mean().pow(2)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        return self.alpha*self.huber(pred, target) + (1-self.alpha)*self.si_log(pred, target)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Optimizer + Cosine + Warmup\n",
    "# -------------------------\n",
    "def get_optimizer_scheduler(model, train_loader, num_epochs, lr=3e-4, weight_decay=1e-2, warmup_frac=0.05):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    warmup_steps = int(total_steps * warmup_frac)\n",
    "\n",
    "    def lr_lambda(step):\n",
    "        if step < warmup_steps:\n",
    "            return step / max(1, warmup_steps)\n",
    "        progress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
    "        return 0.5 * (1 + np.cos(np.pi * progress))\n",
    "\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "    return optimizer, scheduler, total_steps\n",
    "\n",
    "# -------------------------\n",
    "# EMA wrapper\n",
    "# -------------------------\n",
    "def get_ema(model, decay=0.999):\n",
    "    return ExponentialMovingAverage(model.parameters(), decay=decay)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f5951f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-04T21:48:59.865890Z",
     "iopub.status.busy": "2025-09-04T21:48:59.865663Z",
     "iopub.status.idle": "2025-09-04T22:00:46.930083Z",
     "shell.execute_reply": "2025-09-04T22:00:46.929229Z"
    },
    "papermill": {
     "duration": 707.084705,
     "end_time": "2025-09-04T22:00:46.931348",
     "exception": false,
     "start_time": "2025-09-04T21:48:59.846643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb93349beee14080bbc6ebcf42e14947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/49.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "100%|██████████| 19/19 [00:16<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 3.9009 | Val Loss: 0.7338 | RMSE: 0.8566 | MAE: 1.0389\n",
      "✅ Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:11<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 0.6226 | Val Loss: 0.6184 | RMSE: 0.7864 | MAE: 0.9430\n",
      "✅ Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:11<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 0.5925 | Val Loss: 0.5616 | RMSE: 0.7494 | MAE: 0.9153\n",
      "✅ Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:11<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 0.5171 | Val Loss: 0.6946 | RMSE: 0.8334 | MAE: 0.8779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:11<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 0.5066 | Val Loss: 0.5799 | RMSE: 0.7615 | MAE: 0.8978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:11<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 0.5125 | Val Loss: 0.5619 | RMSE: 0.7496 | MAE: 0.8553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:11<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Train Loss: 0.4785 | Val Loss: 0.5660 | RMSE: 0.7523 | MAE: 0.8418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:11<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 0.4813 | Val Loss: 0.4517 | RMSE: 0.6720 | MAE: 0.8179\n",
      "✅ Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:11<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 0.4850 | Val Loss: 0.4936 | RMSE: 0.7026 | MAE: 0.7977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:11<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 0.4855 | Val Loss: 0.5129 | RMSE: 0.7161 | MAE: 0.8162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Train Loss: 0.4644 | Val Loss: 0.5604 | RMSE: 0.7486 | MAE: 0.8584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | Train Loss: 0.4723 | Val Loss: 0.5190 | RMSE: 0.7204 | MAE: 0.8708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | Train Loss: 0.4602 | Val Loss: 0.5398 | RMSE: 0.7347 | MAE: 0.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | Train Loss: 0.4510 | Val Loss: 0.4671 | RMSE: 0.6834 | MAE: 0.7685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | Train Loss: 0.4397 | Val Loss: 0.4046 | RMSE: 0.6361 | MAE: 0.7459\n",
      "✅ Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | Train Loss: 0.4312 | Val Loss: 0.3677 | RMSE: 0.6064 | MAE: 0.6970\n",
      "✅ Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:11<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | Train Loss: 0.4326 | Val Loss: 0.4083 | RMSE: 0.6390 | MAE: 0.6914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | Train Loss: 0.4293 | Val Loss: 0.4231 | RMSE: 0.6505 | MAE: 0.7309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | Train Loss: 0.4096 | Val Loss: 0.3851 | RMSE: 0.6205 | MAE: 0.6740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:11<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | Train Loss: 0.3751 | Val Loss: 0.4322 | RMSE: 0.6574 | MAE: 0.6832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | Train Loss: 0.3875 | Val Loss: 0.3690 | RMSE: 0.6075 | MAE: 0.6602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | Train Loss: 0.3752 | Val Loss: 0.3890 | RMSE: 0.6237 | MAE: 0.6378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | Train Loss: 0.3908 | Val Loss: 0.3825 | RMSE: 0.6185 | MAE: 0.6747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | Train Loss: 0.3890 | Val Loss: 0.3907 | RMSE: 0.6250 | MAE: 0.6520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 | Train Loss: 0.3597 | Val Loss: 0.4156 | RMSE: 0.6446 | MAE: 0.6639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 | Train Loss: 0.3485 | Val Loss: 0.3723 | RMSE: 0.6101 | MAE: 0.6537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 | Train Loss: 0.3419 | Val Loss: 0.3670 | RMSE: 0.6058 | MAE: 0.6624\n",
      "✅ Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 | Train Loss: 0.3391 | Val Loss: 0.3974 | RMSE: 0.6304 | MAE: 0.6663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 | Train Loss: 0.3465 | Val Loss: 0.3916 | RMSE: 0.6258 | MAE: 0.6495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 | Train Loss: 0.3599 | Val Loss: 0.3978 | RMSE: 0.6308 | MAE: 0.6260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 | Train Loss: 0.3409 | Val Loss: 0.3881 | RMSE: 0.6230 | MAE: 0.6573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 | Train Loss: 0.3377 | Val Loss: 0.3136 | RMSE: 0.5600 | MAE: 0.5875\n",
      "✅ Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:11<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 | Train Loss: 0.3581 | Val Loss: 0.3921 | RMSE: 0.6262 | MAE: 0.6226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 | Train Loss: 0.3558 | Val Loss: 0.3608 | RMSE: 0.6007 | MAE: 0.6109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 | Train Loss: 0.3361 | Val Loss: 0.3718 | RMSE: 0.6097 | MAE: 0.6306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 | Train Loss: 0.3272 | Val Loss: 0.3362 | RMSE: 0.5798 | MAE: 0.6047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 | Train Loss: 0.3141 | Val Loss: 0.3818 | RMSE: 0.6179 | MAE: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 | Train Loss: 0.3297 | Val Loss: 0.3748 | RMSE: 0.6122 | MAE: 0.5835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 | Train Loss: 0.3106 | Val Loss: 0.3284 | RMSE: 0.5731 | MAE: 0.6202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 | Train Loss: 0.3054 | Val Loss: 0.3439 | RMSE: 0.5864 | MAE: 0.6008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 | Train Loss: 0.3264 | Val Loss: 0.3344 | RMSE: 0.5783 | MAE: 0.6163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 | Train Loss: 0.3083 | Val Loss: 0.3879 | RMSE: 0.6228 | MAE: 0.6305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 | Train Loss: 0.3217 | Val Loss: 0.3518 | RMSE: 0.5932 | MAE: 0.6005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 | Train Loss: 0.3073 | Val Loss: 0.3378 | RMSE: 0.5812 | MAE: 0.5993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 | Train Loss: 0.3208 | Val Loss: 0.3288 | RMSE: 0.5734 | MAE: 0.6103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 | Train Loss: 0.3138 | Val Loss: 0.3487 | RMSE: 0.5905 | MAE: 0.6026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 | Train Loss: 0.3093 | Val Loss: 0.3843 | RMSE: 0.6199 | MAE: 0.6271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 | Train Loss: 0.3016 | Val Loss: 0.3613 | RMSE: 0.6011 | MAE: 0.6428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 | Train Loss: 0.3211 | Val Loss: 0.3356 | RMSE: 0.5793 | MAE: 0.5957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 | Train Loss: 0.3024 | Val Loss: 0.3020 | RMSE: 0.5496 | MAE: 0.5911\n",
      "✅ Best model saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3020265868076911"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train_depth_model(model,train_dataset, train_loader, val_loader, epochs, freeze_encoder=True,\n",
    "                      epoch_offset=0, total_epochs=50, model_path=\"depth_model.pth\", \n",
    "                      best_val_loss=float(\"inf\")):\n",
    "\n",
    "    criterion = DepthLoss()\n",
    "    scaler = torch.amp.GradScaler()\n",
    "\n",
    "    # Freeze encoder if needed\n",
    "    if freeze_encoder:\n",
    "        for p in model.encoder.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    optimizer, scheduler, total_steps = get_optimizer_scheduler(model, train_loader, epochs)\n",
    "    ema = get_ema(model)\n",
    "\n",
    "    global_step = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_dataset.set_epoch(epoch + epoch_offset, total_epochs=total_epochs)\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for images, depths in tqdm(train_loader):\n",
    "            images, depths = images.to(device), depths.to(device)\n",
    "\n",
    "            # Apply epoch-aware paired transform\n",
    "            # images, depths = paired_transform(images, depths, epoch=epoch + epoch_offset, total_epochs=total_epochs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast(device_type = \"cuda\"):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, depths)\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            ema.update()\n",
    "            global_step += 1\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Validation with EMA weights\n",
    "        ema.store()\n",
    "        ema.copy_to()\n",
    "        model.eval()\n",
    "        val_loss, val_mae = 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, depths in val_loader:\n",
    "                images, depths = images.to(device), depths.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, depths)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                val_mae += (outputs-depths).abs().mean().item() * images.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_mae /= len(val_loader.dataset)\n",
    "        rmse = np.sqrt(val_loss)\n",
    "        ema.restore()\n",
    "\n",
    "        print(f\"Epoch {epoch+1+epoch_offset}/{total_epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | RMSE: {rmse:.4f} | MAE: {val_mae:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"✅ Best model saved.\")\n",
    "\n",
    "    return best_val_loss\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Run training\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Device\n",
    "# --------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------------------------\n",
    "# Model\n",
    "# --------------------------\n",
    "model = DepthModel().to(device)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Datasets & Loaders\n",
    "# --------------------------\n",
    "train_folder = \"/kaggle/input/nyu-depth-split-dataset/nyu_split/train\"\n",
    "valid_folder = \"/kaggle/input/nyu-depth-split-dataset/nyu_split/val\"\n",
    "max_depth = 10\n",
    "\n",
    "train_dataset = DepthDataset(train_folder, paired_transform, max_depth)\n",
    "val_dataset = DepthDataset(valid_folder, paired_transform, max_depth)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# --------------------------\n",
    "# Freeze backbone initially\n",
    "# --------------------------\n",
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# --------------------------\n",
    "# Training Parameters\n",
    "# --------------------------\n",
    "\n",
    "MODEL_PATH = \"/kaggle/working/depth_predictor.pth\"\n",
    "\n",
    "# 1. Train decoder head first\n",
    "best_val_loss = train_depth_model(model, train_dataset, train_loader, val_loader, epochs=num_epoch_head, freeze_encoder=True, \n",
    "                  epoch_offset=0, total_epochs=(num_epoch_head + num_epoch_finetune), model_path= MODEL_PATH)\n",
    "\n",
    "# 2. Fine-tune full model\n",
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "train_depth_model(model, train_dataset, train_loader, val_loader, epochs=num_epoch_finetune, freeze_encoder=False, \n",
    "                  epoch_offset=num_epoch_head, total_epochs=(num_epoch_head + num_epoch_finetune), model_path=\"depth_model.pth\", best_val_loss = best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc9df71d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T22:00:47.067698Z",
     "iopub.status.busy": "2025-09-04T22:00:47.067395Z",
     "iopub.status.idle": "2025-09-04T22:00:47.072916Z",
     "shell.execute_reply": "2025-09-04T22:00:47.072199Z"
    },
    "papermill": {
     "duration": 0.079561,
     "end_time": "2025-09-04T22:00:47.074239",
     "exception": false,
     "start_time": "2025-09-04T22:00:46.994678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # --------------------------\n",
    "# # Testing / Inference\n",
    "# # --------------------------\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(\"Using device:\", device)\n",
    "\n",
    "# # --------------------------\n",
    "# # Test Dataset & DataLoader\n",
    "# # --------------------------\n",
    "# test_folder = \"/kaggle/input/nyu-test-colors-depths/nyu2_test_colors_depths\"\n",
    "# test_dataset = DepthDataset(test_folder, paired_transform, max_depth=10.0)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# # Load trained model\n",
    "# test_model = DepthModel().to(device)\n",
    "# test_model.load_state_dict(torch.load(\n",
    "#     \"/kaggle/input/depthmodel3/pytorch/default/1/depth_classifier.pth\", \n",
    "#     map_location=device\n",
    "# ))\n",
    "# test_model.eval()\n",
    "\n",
    "# # Loss function for evaluation\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# # --------------------------\n",
    "# # Evaluation with tqdm\n",
    "# # --------------------------\n",
    "# val_loss, val_mae = 0.0, 0.0\n",
    "# with torch.no_grad():\n",
    "#     for images, depths in tqdm(test_loader, desc=\"Evaluating on test set\"):\n",
    "#         images, depths = images.to(device), depths.to(device)\n",
    "#         outputs = test_model(images)\n",
    "\n",
    "#         # Loss metrics\n",
    "#         mse_loss = criterion(outputs, depths)\n",
    "#         mae_loss = torch.mean(torch.abs(outputs - depths))\n",
    "\n",
    "#         val_loss += mse_loss.item() * images.size(0)\n",
    "#         val_mae += mae_loss.item() * images.size(0)\n",
    "\n",
    "# val_loss /= len(test_loader.dataset)\n",
    "# val_mae /= len(test_loader.dataset)\n",
    "# val_rmse = np.sqrt(val_loss)\n",
    "\n",
    "# print(f\"✅ Test Results -> MSE: {val_loss:.4f}, RMSE: {val_rmse:.4f} m, MAE: {val_mae:.4f} m\")\n",
    "\n",
    "# # --------------------------\n",
    "# # Visualization\n",
    "# # --------------------------\n",
    "# def show_predictions(model, dataset, num_samples=5):\n",
    "#     model.eval()\n",
    "#     fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "\n",
    "#     for i in tqdm(range(num_samples), desc=\"Visualizing predictions\"):\n",
    "#         color, depth_gt = dataset[i]\n",
    "#         color_batch = color.unsqueeze(0).to(device)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             depth_pred = model(color_batch).cpu().squeeze().numpy()\n",
    "\n",
    "#         depth_gt = depth_gt.squeeze().numpy()\n",
    "\n",
    "#         # Plot RGB\n",
    "#         axes[i, 0].imshow(np.transpose(color.numpy(), (1, 2, 0)))\n",
    "#         axes[i, 0].set_title(\"RGB Input\")\n",
    "#         axes[i, 0].axis(\"off\")\n",
    "\n",
    "#         # Plot Ground Truth Depth\n",
    "#         axes[i, 1].imshow(depth_gt, cmap=\"inferno\")\n",
    "#         axes[i, 1].set_title(\"Ground Truth Depth\")\n",
    "#         axes[i, 1].axis(\"off\")\n",
    "\n",
    "#         # Plot Predicted Depth\n",
    "#         axes[i, 2].imshow(depth_pred, cmap=\"inferno\")\n",
    "#         axes[i, 2].set_title(\"Predicted Depth\")\n",
    "#         axes[i, 2].axis(\"off\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Visualize predictions from test set\n",
    "# show_predictions(test_model, test_dataset, num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1198025,
     "sourceId": 2002504,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8200507,
     "sourceId": 12957283,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8201775,
     "sourceId": 12959543,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 441973,
     "modelInstanceId": 424483,
     "sourceId": 559837,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 441974,
     "modelInstanceId": 424484,
     "sourceId": 559838,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 442315,
     "modelInstanceId": 424827,
     "sourceId": 560631,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 815.345865,
   "end_time": "2025-09-04T22:00:50.257667",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-04T21:47:14.911802",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1420686246484098877b84f8270c73d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ef973d86e13b48b9997dbd738a2e6840",
       "placeholder": "​",
       "style": "IPY_MODEL_a947ab6e97614a3db2d4cc8ea31a45f9",
       "tabbable": null,
       "tooltip": null,
       "value": " 49.3M/49.3M [00:00&lt;00:00, 172MB/s]"
      }
     },
     "3d6837de19ab467e95bb353373e75c63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_45db90ec7a61447097e114b31833f8b3",
       "max": 49335454.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_74e5232f1a99445684c8cc31193e18b6",
       "tabbable": null,
       "tooltip": null,
       "value": 49335454.0
      }
     },
     "45db90ec7a61447097e114b31833f8b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74e5232f1a99445684c8cc31193e18b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "950ee69bab974005a2295e13b91f5460": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a947ab6e97614a3db2d4cc8ea31a45f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b7d750b7f4664a98850c7dbd6ec1b505": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bb93349beee14080bbc6ebcf42e14947": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cf705d33699e40738642602c9e646805",
        "IPY_MODEL_3d6837de19ab467e95bb353373e75c63",
        "IPY_MODEL_1420686246484098877b84f8270c73d8"
       ],
       "layout": "IPY_MODEL_e2bd9fe5b41844feb52966871d182544",
       "tabbable": null,
       "tooltip": null
      }
     },
     "cf705d33699e40738642602c9e646805": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_950ee69bab974005a2295e13b91f5460",
       "placeholder": "​",
       "style": "IPY_MODEL_b7d750b7f4664a98850c7dbd6ec1b505",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "e2bd9fe5b41844feb52966871d182544": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef973d86e13b48b9997dbd738a2e6840": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
